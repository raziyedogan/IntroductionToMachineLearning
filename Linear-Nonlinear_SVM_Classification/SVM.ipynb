{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a825cd30",
   "metadata": {},
   "source": [
    "Sınıflandırma problemlerindeki asıl amacımız gelecek verinin hangi sınıfta yer alacağına karar vermektir. Bu amaç doğrultusunda kullandığımız Destek Vektör Makineleri (SVM), düzlem üzerindeki noktaların bir doğru veya hiper düzlem ile ayrıştırılmasını ve sınıflandırılmasını sağlar. \n",
    "\n",
    "SVM'ler, özellikle karmaşık ancak küçük veya orta büyüklükteki veri setlerinin sınıflandırılması için çok uygundur. \n",
    "SVM sonucunda bir olasılık değeri elde edilmez, direk verinin hangi sınıfa ait olduğu bilgisi elde edilir. \n",
    "SVM'ler Linear SVM classification ve Nonlinear SVM classification şeklinde düşünülür. Veri setinin doğrusal olarak ayrılabilmesi durumu Linear SVM Classification'dur. Veri setinin doğrusal olarak ayrılamadığı durum ise Nonlinear SVM classification'dur.\n",
    "\n",
    "SVM çalışma mantığı şu şekildedir: Her iki sınıftanda birbirlerine doğru en uçtaki noktalar seçilir. Bu noktalar 'support vectors' olarak adlandırılır. Bu seçilen noktalar arasına düz çizgi (Linear SVM classification) çekilir. Çizgi iki sınıfı ayırır. Belirlediğimiz çizgi konumunu duruma göre sağa veya sola çekebiliriz. Bu çizgi, bir SVM sınıflandırıcısının karar sınırını temsil eder. Ve çizgi, en yakın noktalardan (bir başka deyişle eğitim örneklerinden) mümkün olduğunca uzak durur. Seçilen noktalar arasında kalan bölgeye 'margin' denir. Margin ne kadar geniş ise sınıflar o kadar iyi ayrıştırılır. \n",
    "Şunuda söylemeliyim ki, SVM'ler özellik ölçeklerine duyarlıdır ve özellik ölçeklendirme (örneğin, Scikit-Learn'in StandardScaler'i) ile karar sınırı çok daha iyi görünür.\n",
    "\n",
    "Veri setinin doğrusal olarak ayrılabildiği durumda bu bahsettiklerim gayet uygulanabilir. Fakat doğrusal olmayan (nonlinear) veri setlerini işlemeye yönelik bir yaklaşım, polinom özellikleri gibi daha fazla özellik eklemektir ve bazı durumlarda bu, doğrusal olarak ayrılabilir bir veri kümesiyle sonuçlanabilir. Burada bir matematik tekniği olan 'Kernel Trick' kavramıyla çok sık karşılaşacaksınız. Elimizdeki koordinatları belirli Kernel Fonksiyonları ile çarparak çok daha anlamlı hale getirebiliyoruz. Çok yüksek dereceli polinomlarda bile, aslında eklemeye gerek kalmadan birçok polinom özelliği eklemişsiniz gibi aynı sonucu elde etmeyi mümkün kılar. Şimdi biraz hayal gücümüzü çalıştıralım. Bütün noktaların yan yana aynı hizzada sıralı bir şekilde olduğunu düşünün. Bu durumda veri setini doğrusal olarak ayıramayız. Eğer tüm özelliklerin (noktaların) karelerini alırsak, noktaların yeni konumları mükemmel bir şekilde lineer olarak ayrılabilir.\n",
    "\n",
    "Formülü inceleyelim:\n",
    "w^T . x + b\n",
    "Burada, w; ağırlık vektörü , x; girdi vektörü , b; sapmadır. Yeni bir değer için elde edilen sonuç 0'dan küçük ise, karar çizgisinin altında kalan sınıfa daha yakın olacaktır. Sonuç 0'a eşit veya büyükse, karar çizgisinin üst tarafında kalan alana daha yakın olacaktır.\n",
    "Bu bahsedilenler margin bölgesinde bir örnek (nokta) olmadığı durumunda rahatlıkla uygulanabilir. Tabi ki her zaman her şey bu kadar iyi olmayabilir. Eğer örnekler margin bölgesinde ise buna 'soft margin' denir. Soft margin'de outlier (aykırı nokta yani sınıfından uzaktaki nokta) devre dışı bırakılır. Hard Margin, veriler doğrusal olarak ayrılabiliyorsa çalışır ve aykırı değerlere karşı oldukça duyarlıdır. Bu yüzden bazı durumlarda Soft Margin’i tercih etmemiz gerekebilir. \n",
    "Bu dengeyi SVM içerisindeki C hiperparametresi ile kontrol edebiliriz. C ne kadar büyükse Margin o kadar dardır. Ayrıca model overfit olursa C’yi azaltmamız gerekir.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "34fe8e34",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import datasets\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import LinearSVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e2770768",
   "metadata": {},
   "outputs": [],
   "source": [
    "#iris veri setini çağıralım.\n",
    "iris = datasets.load_iris()\n",
    "X = iris[\"data\"][:, (2, 3)] # petal length, petal width\n",
    "y = (iris[\"target\"] == 2).astype(np.float64) # Iris-Virginica"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7be3835a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('scaler', StandardScaler()),\n",
       "                ('linear_svc', LinearSVC(C=1, loss='hinge'))])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Pipeline yapısı içerisine modelin özelliklerini yerleştiririz. yapı içerisinde bulunan StandardScaler() ile özellikleri \n",
    "ölçeklendirdiğimize dikkat edelim. C değeri 1 ve LinearSVC sınıfını kullanarak Iris-Virginica çiçeklerini algılamak için \n",
    "doğrusal(linear) bir SVM modelini eğitelim:\n",
    "\"\"\"\n",
    "svm_clf = Pipeline([\n",
    "(\"scaler\", StandardScaler()),\n",
    "(\"linear_svc\", LinearSVC(C=1, loss=\"hinge\")),\n",
    "])\n",
    "svm_clf.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "32beccd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "predict = svm_clf.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3080ab1a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[98,  2],\n",
       "       [ 4, 46]], dtype=int64)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_matrix(y, predict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73c04a49",
   "metadata": {},
   "source": [
    "Sınıflandırıcımızın performansını değerlendirmek amacıyla Confusion Matrix kullandık. \n",
    "Output:\n",
    "array([[98,  2],\n",
    "       [ 4, 46]], dtype=int64)\n",
    "Çıktıda görüldüğü üzere 2+4=6 yanlış tahmin ve 98+46=144 doğru tahmin elde edilmiştir."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "222e1fb6",
   "metadata": {},
   "source": [
    "Nonlinear SVM Classification'dan yukarıda bahsettik. Şimdi de buna dair bir uygulama yapalım. make_moons() fonksiyonunu kullanarak veri setini çağıralım. Bu veri seti, veri noktalarının iki yarım daire şeklinde şekillendirildiği ikili sınıflandırma için bir oyuncak veri setidir."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f28ccf16",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_moons\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import PolynomialFeatures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0ac236b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('poly_features', PolynomialFeatures(degree=3)),\n",
       "                ('scaler', StandardScaler()),\n",
       "                ('svm_clf', LinearSVC(C=10, loss='hinge'))])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "polynomial_svm_clf = Pipeline([\n",
    "(\"poly_features\", PolynomialFeatures(degree=3)),\n",
    "(\"scaler\", StandardScaler()),\n",
    "(\"svm_clf\", LinearSVC(C=10, loss=\"hinge\"))\n",
    "])\n",
    "polynomial_svm_clf.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "202b9142",
   "metadata": {},
   "outputs": [],
   "source": [
    "predict2 = polynomial_svm_clf.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "11c6f658",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[97,  3],\n",
       "       [ 3, 47]], dtype=int64)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_matrix(y, predict2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1715f92",
   "metadata": {},
   "source": [
    "Confusion Matrix çıktısı:\n",
    "array([[97,  3],\n",
    "       [ 3, 47]], dtype=int64)\n",
    "şeklindedir. 3+3=6 yanlış tahmin ve 97+47=144 doğru tahmin elde edilmiştir."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e62c200",
   "metadata": {},
   "source": [
    "Birde yukarıda bahsettiğim kernel trick'e dair bir uygulama yapalım:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "83b7adde",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('scaler', StandardScaler()),\n",
       "                ('svm_clf', SVC(C=5, coef0=1, kernel='poly'))])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "poly_kernel_svm_clf = Pipeline([\n",
    "(\"scaler\", StandardScaler()),\n",
    "(\"svm_clf\", SVC(kernel=\"poly\", degree=3, coef0=1, C=5))\n",
    "])\n",
    "poly_kernel_svm_clf.fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bf75ca4",
   "metadata": {},
   "source": [
    "coef0 hiperparametresi, modelin düşük dereceli polinomlara karşı yüksek dereceli polinomlardan ne kadar etkilendiğini kontrol eder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7bd585b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "predict3 = poly_kernel_svm_clf.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "153aa162",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[97,  3],\n",
       "       [ 3, 47]], dtype=int64)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_matrix(y, predict3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67b22e13",
   "metadata": {},
   "source": [
    "Output: \n",
    "array([[97,  3],\n",
    "       [ 3, 47]], dtype=int64)\n",
    "şeklindedir. 3+3=6 yanlış tahmin ve 97+47=144 doğru tahmin elde edilmiştir.\n",
    "ln [7] kod bloğu ile aynı sonucu verdiğine dikkat edin :)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
